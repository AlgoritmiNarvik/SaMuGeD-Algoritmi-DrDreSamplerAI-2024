<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>Markmap</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.17.0/dist/style.css">
</head>
<body>
<svg id="mindmap"></svg>
<script src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-view@0.17.0/dist/browser/index.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.17.0/dist/index.js"></script><script>(()=>{setTimeout(()=>{const{markmap:O,mm:h}=window,M=new O.Toolbar;M.attach(h);const oe=M.render();oe.setAttribute("style","position:absolute;bottom:20px;right:20px"),document.body.append(oe)})})()</script><script>((i,L,f,r)=>{const w=i();window.mm=w.Markmap.create("svg#mindmap",(L||w.deriveOptions)(r),f)})(()=>window.markmap,null,{"content":"Music Generation System Project Roadmap","children":[{"content":"Project Goal","children":[],"payload":{"lines":"2,3"}},{"content":"Step 1: Research and Analysis of Existing Resources","children":[{"content":"<strong>Study existing MIDI datasets and tools:</strong>","children":[{"content":"<strong>AAM Dataset</strong>","children":[{"content":"Explore 3000 artificial music tracks","children":[],"payload":{"lines":"8,9"}},{"content":"Rich annotations for various music information retrieval (MIR) tasks","children":[],"payload":{"lines":"9,10"}}],"payload":{"lines":"7,10"}},{"content":"<strong>ComMU Dataset</strong>","children":[{"content":"Utilize 11,144 MIDI samples created by professional composers","children":[],"payload":{"lines":"11,12"}},{"content":"12 metadata fields for generating diverse music","children":[],"payload":{"lines":"12,13"}}],"payload":{"lines":"10,13"}},{"content":"<strong>ArtificialSongGenerator</strong>","children":[{"content":"Tool for automatically generating MIDI files and audio tracks","children":[],"payload":{"lines":"14,15"}},{"content":"Uses algorithmic composition","children":[],"payload":{"lines":"15,16"}}],"payload":{"lines":"13,16"}},{"content":"<strong>FMP Notebooks</strong>","children":[{"content":"Educational materials and code examples","children":[],"payload":{"lines":"17,18"}},{"content":"Various music information retrieval tasks","children":[],"payload":{"lines":"18,20"}}],"payload":{"lines":"16,20"}}],"payload":{"lines":"6,20"}}],"payload":{"lines":"5,6"}},{"content":"Step 2: Creating and Annotating the Dataset","children":[{"content":"<strong>Data Preparation:</strong>","children":[{"content":"Collect existing MIDI files from various sources (AAM, ComMU)","children":[],"payload":{"lines":"22,23"}},{"content":"Analyze collected MIDI files","children":[],"payload":{"lines":"23,24"}},{"content":"Use ArtificialSongGenerator to create new MIDI files and corresponding audio tracks","children":[],"payload":{"lines":"24,25"}}],"payload":{"lines":"21,25"}},{"content":"<strong>Data Annotation:</strong>","children":[{"content":"Develop annotation standards for key musical features:","children":[{"content":"Onsets","children":[],"payload":{"lines":"27,28"}},{"content":"Pitches","children":[],"payload":{"lines":"28,29"}},{"content":"Instruments","children":[],"payload":{"lines":"29,30"}},{"content":"Keys","children":[],"payload":{"lines":"30,31"}},{"content":"Tempos","children":[],"payload":{"lines":"31,32"}},{"content":"Segments","children":[],"payload":{"lines":"32,33"}},{"content":"Melodies","children":[],"payload":{"lines":"33,34"}},{"content":"Beats","children":[],"payload":{"lines":"34,35"}},{"content":"Chords","children":[],"payload":{"lines":"35,36"}}],"payload":{"lines":"26,36"}},{"content":"Automatically annotate collected data using available tools","children":[],"payload":{"lines":"36,37"}},{"content":"Manually verify and refine annotations","children":[],"payload":{"lines":"37,39"}}],"payload":{"lines":"25,39"}}],"payload":{"lines":"20,21"}},{"content":"Step 3: Developing and Testing Algorithms","children":[{"content":"<strong>Music Segmentation:</strong>","children":[{"content":"Develop algorithms for segmenting music into manageable parts (chorus, verse, etc.)","children":[],"payload":{"lines":"41,42"}},{"content":"Test segmentation algorithms using data from AAM and ComMU","children":[],"payload":{"lines":"42,43"}},{"content":"Optimize segmentation algorithms based on test results","children":[],"payload":{"lines":"43,44"}}],"payload":{"lines":"40,44"}},{"content":"<strong>Pattern Recognition:</strong>","children":[{"content":"Use machine learning methods (RNN, VAE, transformers) for recognizing musical patterns","children":[],"payload":{"lines":"45,46"}},{"content":"Evaluate algorithm performance using the annotated dataset","children":[],"payload":{"lines":"46,47"}},{"content":"Improve algorithms based on evaluation results","children":[],"payload":{"lines":"47,48"}}],"payload":{"lines":"44,48"}},{"content":"<strong>Music Generation:</strong>","children":[{"content":"Develop algorithms for generating new musical compositions","children":[],"payload":{"lines":"49,50"}},{"content":"Test music generation algorithms using various approaches (algorithmic composition, deep learning)","children":[],"payload":{"lines":"50,51"}},{"content":"Optimize algorithms to create high-quality and diverse music","children":[],"payload":{"lines":"51,53"}}],"payload":{"lines":"48,53"}}],"payload":{"lines":"39,40"}},{"content":"Step 4: Optimization and Enhancement","children":[{"content":"<strong>Scaling and Computational Resources:</strong>","children":[{"content":"Gradually scale up tests to larger datasets","children":[],"payload":{"lines":"55,56"}},{"content":"Use external computational resources as needed","children":[],"payload":{"lines":"56,57"}},{"content":"Utilize Google Colab and a MacBook with M1 Pro processor for local tests","children":[],"payload":{"lines":"57,58"}}],"payload":{"lines":"54,58"}},{"content":"<strong>Automation and Verification:</strong>","children":[{"content":"Develop methods for automatic evaluation of generated music","children":[],"payload":{"lines":"59,60"}},{"content":"Implement manual verification processes to ensure data quality","children":[],"payload":{"lines":"60,61"}},{"content":"Include human-in-the-loop reinforcement learning for manual result verification","children":[],"payload":{"lines":"61,63"}}],"payload":{"lines":"58,63"}}],"payload":{"lines":"53,54"}},{"content":"Step 5: Publications and Further Research","children":[{"content":"<strong>Publications:</strong>","children":[{"content":"Prepare scientific papers based on the created dataset and developed algorithms","children":[],"payload":{"lines":"65,66"}},{"content":"Submit papers to relevant conferences and journals","children":[],"payload":{"lines":"66,67"}}],"payload":{"lines":"64,67"}},{"content":"<strong>Collaborations and Media Applications:</strong>","children":[{"content":"Explore potential applications of the music generation system in media","children":[],"payload":{"lines":"68,69"}},{"content":"Identify potential collaborators and partnership opportunities","children":[],"payload":{"lines":"69,70"}},{"content":"Develop plans for further research and continuous improvement of the music generation system","children":[],"payload":{"lines":"70,71"}}],"payload":{"lines":"67,71"}}],"payload":{"lines":"63,64"}}],"payload":{"lines":"0,1"}},null)</script>
</body>
</html>
