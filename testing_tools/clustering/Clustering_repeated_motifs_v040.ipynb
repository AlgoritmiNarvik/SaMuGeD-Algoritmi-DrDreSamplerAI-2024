{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mido\n",
    "%pip install numpy\n",
    "%pip install pretty_midi\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install faiss-cpu  # for similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import os\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "import faiss\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: ipynb has different paths concept, use full path for ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    \"\"\"\n",
    "    Extract features from a MIDI file using a dictionary structure.\n",
    "    Focuses on pitch, duration, rhythm, and tempo features.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        midi_data = pretty_midi.PrettyMIDI(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    # Initialize feature structure\n",
    "    detailed_features = {\n",
    "        'pitch_features': {'values': []},\n",
    "        'duration_features': {'values': []},\n",
    "        'rhythm_features': {\n",
    "            'onset_times': [],\n",
    "            'ioi_values': [],\n",
    "            'beat_positions': [],\n",
    "            'syncopation': []\n",
    "        },\n",
    "        'tempo': midi_data.estimate_tempo(),\n",
    "        'time_signature': None,\n",
    "        'key_signature': None\n",
    "    }\n",
    "    \n",
    "    # Extract time and key signatures\n",
    "    for ts in midi_data.time_signature_changes:\n",
    "        detailed_features['time_signature'] = f\"{ts.numerator}/{ts.denominator}\"\n",
    "        break\n",
    "        \n",
    "    for ks in midi_data.key_signature_changes:\n",
    "        detailed_features['key_signature'] = ks.key_number\n",
    "        break\n",
    "\n",
    "    # Collect note features and onset times\n",
    "    for instrument in midi_data.instruments:\n",
    "        if not instrument.is_drum:\n",
    "            for note in instrument.notes:\n",
    "                detailed_features['pitch_features']['values'].append(note.pitch)\n",
    "                detailed_features['duration_features']['values'].append(note.end - note.start)\n",
    "                detailed_features['rhythm_features']['onset_times'].append(note.start)\n",
    "    \n",
    "    if not detailed_features['pitch_features']['values']:\n",
    "        return None\n",
    "\n",
    "    # Process rhythm features\n",
    "    if len(detailed_features['rhythm_features']['onset_times']) > 0:\n",
    "        onset_times = sorted(detailed_features['rhythm_features']['onset_times'])\n",
    "        ioi_values = np.diff(onset_times)\n",
    "        detailed_features['rhythm_features']['ioi_values'] = ioi_values.tolist()\n",
    "        \n",
    "        if detailed_features['time_signature']:\n",
    "            beats_per_measure = int(detailed_features['time_signature'].split('/')[0])\n",
    "            beat_duration = 60.0 / detailed_features['tempo']\n",
    "            beat_positions = [t % (beats_per_measure * beat_duration) / beat_duration \n",
    "                            for t in onset_times]\n",
    "            detailed_features['rhythm_features']['beat_positions'] = beat_positions\n",
    "            \n",
    "            syncopation = [1 if not np.isclose(pos % 1, 0, atol=0.1) else 0 \n",
    "                          for pos in beat_positions]\n",
    "            detailed_features['rhythm_features']['syncopation'] = syncopation\n",
    "\n",
    "    # Calculate statistics\n",
    "    for feature_type in ['pitch_features', 'duration_features']:\n",
    "        values = np.array(detailed_features[feature_type]['values'])\n",
    "        detailed_features[feature_type].update({\n",
    "            'values': values.tolist(),\n",
    "            'mean': float(np.mean(values)),\n",
    "            'std': float(np.std(values)),\n",
    "            'min': float(np.min(values)),\n",
    "            'max': float(np.max(values))\n",
    "        })\n",
    "    \n",
    "    # Add rhythm statistics\n",
    "    if len(detailed_features['rhythm_features']['ioi_values']) > 0:\n",
    "        ioi_values = np.array(detailed_features['rhythm_features']['ioi_values'])\n",
    "        detailed_features['rhythm_features'].update({\n",
    "            'ioi_mean': float(np.mean(ioi_values)),\n",
    "            'ioi_std': float(np.std(ioi_values)),\n",
    "            'syncopation_ratio': float(np.mean(detailed_features['rhythm_features']['syncopation']))\n",
    "            if detailed_features['rhythm_features']['syncopation'] else 0.0\n",
    "        })\n",
    "    else:\n",
    "        detailed_features['rhythm_features'].update({\n",
    "            'ioi_mean': 0.0,\n",
    "            'ioi_std': 0.0,\n",
    "            'syncopation_ratio': 0.0\n",
    "        })\n",
    "    \n",
    "    # Create simplified features for clustering\n",
    "    simplified_features = {\n",
    "        'tempo': float(detailed_features['tempo']),\n",
    "        'pitch_mean': float(detailed_features['pitch_features']['mean']),\n",
    "        'pitch_std': float(detailed_features['pitch_features']['std']),\n",
    "        'duration_mean': float(detailed_features['duration_features']['mean']),\n",
    "        'duration_std': float(detailed_features['duration_features']['std']),\n",
    "        'ioi_mean': float(detailed_features['rhythm_features']['ioi_mean']),\n",
    "        'ioi_std': float(detailed_features['rhythm_features']['ioi_std']),\n",
    "        'syncopation_ratio': float(detailed_features['rhythm_features']['syncopation_ratio'])\n",
    "    }\n",
    "    \n",
    "    return simplified_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Musical Feature Explanations\n",
    "\n",
    "## Basic Features\n",
    "- **tempo**: Speed of the music in beats per minute (BPM)\n",
    "  - Example: 188.05 BPM = Very fast, energetic tempo\n",
    "  - Range: Usually 60-200 BPM\n",
    "\n",
    "## Pitch Features\n",
    "- **pitch_mean**: Average MIDI note number (0-127)\n",
    "  - Example: 50.37 â‰ˆ D3 note\n",
    "  - Range: 0 (lowest) to 127 (highest)\n",
    "  - Reference: Middle C (C4) = 60\n",
    "\n",
    "- **pitch_std**: How spread out the notes are from the mean\n",
    "  - Example: 7.31 = Notes span about 1 octave\n",
    "  - Higher value = More melodic variation\n",
    "\n",
    "## Timing Features\n",
    "- **duration_mean**: Average note length in seconds\n",
    "  - Example: 0.22s = Mostly short notes\n",
    "  - Lower values = Faster, staccato notes\n",
    "  - Higher values = Longer, sustained notes\n",
    "\n",
    "- **duration_std**: Variation in note lengths\n",
    "  - Example: 0.07s = Fairly consistent note lengths\n",
    "  - Higher value = More rhythmic variety\n",
    "\n",
    "## Rhythm Features\n",
    "- **ioi_mean**: Average time between note onsets (Inter-Onset Interval)\n",
    "  - Example: 1.84s = Relatively sparse notes\n",
    "  - Lower values = Notes close together\n",
    "  - Higher values = More space between notes\n",
    "\n",
    "- **ioi_std**: Variation in timing between notes\n",
    "  - Example: 14.67 = Very irregular rhythm\n",
    "  - Higher value = More rhythmic complexity\n",
    "\n",
    "- **syncopation_ratio**: Proportion of notes that fall between beats\n",
    "  - Example: 0.96 = Almost all notes are syncopated\n",
    "  - Range: 0 (on-beat) to 1 (all syncopated)\n",
    "  - Higher value = More rhythmic tension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Search Index\n",
    "FAISS for efficient similarity searches in high-dimensional spaces\n",
    "\n",
    "FAISS -- Facebook AI Similarity Search (https://ai.meta.com/tools/faiss/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_faiss_index(feature_list):\n",
    "    \"\"\"\n",
    "    - Fit a StandardScaler on feature_list\n",
    "    - Scale the data\n",
    "    - Build a FAISS IndexFlatL2\n",
    "    Returns (faiss_index, scaler, scaled_features).\n",
    "    \"\"\"\n",
    "    # Convert list to numpy array\n",
    "    feature_matrix = np.array(feature_list, dtype='float32')\n",
    "    \n",
    "    # Fit scaler\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(feature_matrix)\n",
    "    \n",
    "    # Build FAISS index\n",
    "    d = scaled_features.shape[1]\n",
    "    index = faiss.IndexFlatL2(d)\n",
    "    index.add(scaled_features)\n",
    "    \n",
    "    return index, scaler, scaled_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_midi(query_file_path, file_names, faiss_index, scaler, k=5):\n",
    "    \"\"\"\n",
    "    Given a query MIDI file and a FAISS index, returns top-k similar files.\n",
    "    \"\"\"\n",
    "    query_feats = extract_features(query_file_path)\n",
    "    if query_feats is None:\n",
    "        print(\"Failed to extract features from query file.\")\n",
    "        return [], []\n",
    "    \n",
    "    query_vector = np.array([\n",
    "        query_feats['tempo'],\n",
    "        query_feats['pitch_mean'],\n",
    "        query_feats['pitch_std'],\n",
    "        query_feats['duration_mean'],\n",
    "        query_feats['duration_std'],\n",
    "        query_feats['ioi_mean'],\n",
    "        query_feats['ioi_std'],\n",
    "        query_feats['syncopation_ratio']\n",
    "    ], dtype='float32').reshape(1, -1)\n",
    "    \n",
    "    # Scale the query with the same scaler\n",
    "    query_scaled = scaler.transform(query_vector)\n",
    "    \n",
    "    # Search top-k\n",
    "    distances, indices = faiss_index.search(query_scaled.astype('float32'), k)\n",
    "    \n",
    "    # Retrieve file names and distances\n",
    "    results_files = [file_names[i] for i in indices[0]]\n",
    "    results_distances = distances[0]\n",
    "    \n",
    "    return results_files, results_distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset_folder):\n",
    "    \"\"\"\n",
    "    Extract features from all MIDI files within a folder structure.\n",
    "    Returns (feature_list, file_names).\n",
    "    \"\"\"\n",
    "    feature_list = []\n",
    "    file_names = []\n",
    "    \n",
    "    for root, _, files in os.walk(dataset_folder):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.mid', '.midi')):\n",
    "                midi_path = os.path.join(root, file)\n",
    "                feats = extract_features(midi_path)\n",
    "                if feats is not None:\n",
    "                    feature_vec = [\n",
    "                        feats['tempo'],\n",
    "                        feats['pitch_mean'],\n",
    "                        feats['pitch_std'],\n",
    "                        feats['duration_mean'],\n",
    "                        feats['duration_std'],\n",
    "                        feats['ioi_mean'],\n",
    "                        feats['ioi_std'],\n",
    "                        feats['syncopation_ratio']\n",
    "                    ]\n",
    "                    feature_list.append(feature_vec)\n",
    "                    file_names.append(midi_path)\n",
    "    \n",
    "    if not feature_list:\n",
    "        raise ValueError(\"No valid MIDI files found in the dataset folder.\")\n",
    "    \n",
    "    return feature_list, file_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Suppose we have a dataset folder\n",
    "    dataset_path = \"/path/to/your/midi/dataset\"\n",
    "    \n",
    "    # Process dataset -> (feature_list, file_names)\n",
    "    feature_list, file_names = process_dataset(dataset_path)\n",
    "    \n",
    "    # Build FAISS index\n",
    "    faiss_index, scaler, _ = build_faiss_index(feature_list)\n",
    "    \n",
    "    # Query\n",
    "    query_midi_path = \"/path/to/query/file.mid\"\n",
    "    k_neighbors = 5\n",
    "    \n",
    "    similar_files, dists = find_similar_midi(query_midi_path, file_names, faiss_index, scaler, k=k_neighbors)\n",
    "    \n",
    "    print(f\"\\nQuery: {query_midi_path}\")\n",
    "    print(f\"Top {k_neighbors} similar files:\")\n",
    "    for fpath, dist in zip(similar_files, dists):\n",
    "        # Optionally convert distance -> similarity ( e.g. 1/(1+dist) )\n",
    "        sim = 1.0 / (1.0 + dist)\n",
    "        print(f\"\\tFile: {fpath} | Distance: {dist:.4f} | Similarity: {sim:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
