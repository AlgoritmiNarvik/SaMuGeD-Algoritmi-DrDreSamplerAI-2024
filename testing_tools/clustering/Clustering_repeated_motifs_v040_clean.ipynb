{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mido\n",
    "%pip install numpy\n",
    "%pip install pretty_midi\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install faiss-cpu  # for similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import unittest\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import pretty_midi\n",
    "import faiss\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: ipynb has different paths concept, use full path for ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    \"\"\"\n",
    "    Extract features from a MIDI file using a dictionary structure.\n",
    "    Focuses on pitch, duration, rhythm, and tempo features.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        midi_data = pretty_midi.PrettyMIDI(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    # Initialize feature structure\n",
    "    detailed_features = {\n",
    "        'pitch_features': {'values': []},\n",
    "        'duration_features': {'values': []},\n",
    "        'rhythm_features': {\n",
    "            'onset_times': [],\n",
    "            'ioi_values': [],\n",
    "            'beat_positions': [],\n",
    "            'syncopation': []\n",
    "        },\n",
    "        'tempo': None,  # We'll set this below\n",
    "        'time_signature': None,\n",
    "        'key_signature': None\n",
    "    }\n",
    "    \n",
    "    # Try to estimate tempo, fall back to initial tempo if that fails\n",
    "    try:\n",
    "        detailed_features['tempo'] = midi_data.estimate_tempo()\n",
    "    except ValueError:\n",
    "        # Get initial tempo from the MIDI file\n",
    "        if len(midi_data.get_tempo_changes()) > 0:\n",
    "            detailed_features['tempo'] = midi_data.get_tempo_changes()[1][0]\n",
    "        else:\n",
    "            detailed_features['tempo'] = 120.0  # Default fallback tempo\n",
    "    \n",
    "    # Extract time and key signatures\n",
    "    for ts in midi_data.time_signature_changes:\n",
    "        detailed_features['time_signature'] = f\"{ts.numerator}/{ts.denominator}\"\n",
    "        break\n",
    "        \n",
    "    for ks in midi_data.key_signature_changes:\n",
    "        detailed_features['key_signature'] = ks.key_number\n",
    "        break\n",
    "\n",
    "    # Collect note features and onset times\n",
    "    for instrument in midi_data.instruments:\n",
    "        if not instrument.is_drum:\n",
    "            for note in instrument.notes:\n",
    "                detailed_features['pitch_features']['values'].append(note.pitch)\n",
    "                detailed_features['duration_features']['values'].append(note.end - note.start)\n",
    "                detailed_features['rhythm_features']['onset_times'].append(note.start)\n",
    "    \n",
    "    if not detailed_features['pitch_features']['values']:\n",
    "        return None\n",
    "\n",
    "    # Process rhythm features\n",
    "    if len(detailed_features['rhythm_features']['onset_times']) > 0:\n",
    "        onset_times = sorted(detailed_features['rhythm_features']['onset_times'])\n",
    "        ioi_values = np.diff(onset_times)\n",
    "        detailed_features['rhythm_features']['ioi_values'] = ioi_values.tolist()\n",
    "        \n",
    "        if detailed_features['time_signature']:\n",
    "            beats_per_measure = int(detailed_features['time_signature'].split('/')[0])\n",
    "            beat_duration = 60.0 / detailed_features['tempo']\n",
    "            beat_positions = [t % (beats_per_measure * beat_duration) / beat_duration \n",
    "                            for t in onset_times]\n",
    "            detailed_features['rhythm_features']['beat_positions'] = beat_positions\n",
    "            \n",
    "            syncopation = [1 if not np.isclose(pos % 1, 0, atol=0.1) else 0 \n",
    "                          for pos in beat_positions]\n",
    "            detailed_features['rhythm_features']['syncopation'] = syncopation\n",
    "\n",
    "    # Calculate statistics\n",
    "    for feature_type in ['pitch_features', 'duration_features']:\n",
    "        values = np.array(detailed_features[feature_type]['values'])\n",
    "        detailed_features[feature_type].update({\n",
    "            'values': values.tolist(),\n",
    "            'mean': float(np.mean(values)),\n",
    "            'std': float(np.std(values)),\n",
    "            'min': float(np.min(values)),\n",
    "            'max': float(np.max(values))\n",
    "        })\n",
    "    \n",
    "    # Add rhythm statistics\n",
    "    if len(detailed_features['rhythm_features']['ioi_values']) > 0:\n",
    "        ioi_values = np.array(detailed_features['rhythm_features']['ioi_values'])\n",
    "        detailed_features['rhythm_features'].update({\n",
    "            'ioi_mean': float(np.mean(ioi_values)),\n",
    "            'ioi_std': float(np.std(ioi_values)),\n",
    "            'syncopation_ratio': float(np.mean(detailed_features['rhythm_features']['syncopation']))\n",
    "            if detailed_features['rhythm_features']['syncopation'] else 0.0\n",
    "        })\n",
    "    else:\n",
    "        detailed_features['rhythm_features'].update({\n",
    "            'ioi_mean': 0.0,\n",
    "            'ioi_std': 0.0,\n",
    "            'syncopation_ratio': 0.0\n",
    "        })\n",
    "    \n",
    "    # Create simplified features for clustering\n",
    "    simplified_features = {\n",
    "        'tempo': float(detailed_features['tempo']),\n",
    "        'pitch_mean': float(detailed_features['pitch_features']['mean']),\n",
    "        'pitch_std': float(detailed_features['pitch_features']['std']),\n",
    "        'duration_mean': float(detailed_features['duration_features']['mean']),\n",
    "        'duration_std': float(detailed_features['duration_features']['std']),\n",
    "        'ioi_mean': float(detailed_features['rhythm_features']['ioi_mean']),\n",
    "        'ioi_std': float(detailed_features['rhythm_features']['ioi_std']),\n",
    "        'syncopation_ratio': float(detailed_features['rhythm_features']['syncopation_ratio'])\n",
    "    }\n",
    "    \n",
    "    return simplified_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Musical Feature Explanations\n",
    "\n",
    "## Basic Features\n",
    "- **tempo**: Speed of the music in beats per minute (BPM)\n",
    "  - Example: 188.05 BPM = Very fast, energetic tempo\n",
    "  - Range: Usually 60-200 BPM\n",
    "\n",
    "## Pitch Features\n",
    "- **pitch_mean**: Average MIDI note number (0-127)\n",
    "  - Example: 50.37 â‰ˆ D3 note\n",
    "  - Range: 0 (lowest) to 127 (highest)\n",
    "  - Reference: Middle C (C4) = 60\n",
    "\n",
    "- **pitch_std**: How spread out the notes are from the mean\n",
    "  - Example: 7.31 = Notes span about 1 octave\n",
    "  - Higher value = More melodic variation\n",
    "\n",
    "## Timing Features\n",
    "- **duration_mean**: Average note length in seconds\n",
    "  - Example: 0.22s = Mostly short notes\n",
    "  - Lower values = Faster, staccato notes\n",
    "  - Higher values = Longer, sustained notes\n",
    "\n",
    "- **duration_std**: Variation in note lengths\n",
    "  - Example: 0.07s = Fairly consistent note lengths\n",
    "  - Higher value = More rhythmic variety\n",
    "\n",
    "## Rhythm Features\n",
    "- **ioi_mean**: Average time between note onsets (Inter-Onset Interval)\n",
    "  - Example: 1.84s = Relatively sparse notes\n",
    "  - Lower values = Notes close together\n",
    "  - Higher values = More space between notes\n",
    "\n",
    "- **ioi_std**: Variation in timing between notes\n",
    "  - Example: 14.67 = Very irregular rhythm\n",
    "  - Higher value = More rhythmic complexity\n",
    "\n",
    "- **syncopation_ratio**: Proportion of notes that fall between beats\n",
    "  - Example: 0.96 = Almost all notes are syncopated\n",
    "  - Range: 0 (on-beat) to 1 (all syncopated)\n",
    "  - Higher value = More rhythmic tension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Search Index\n",
    "FAISS for efficient similarity searches in high-dimensional spaces\n",
    "\n",
    "FAISS -- Facebook AI Similarity Search (https://ai.meta.com/tools/faiss/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: check what happens if inside a midi there is only one note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_faiss_index(feature_list):\n",
    "    \"\"\"\n",
    "    - Fit a StandardScaler on feature_list\n",
    "    - Scale the data\n",
    "    - Build a FAISS IndexFlatL2\n",
    "    Returns (faiss_index, scaler, scaled_features).\n",
    "    \"\"\"\n",
    "    # Convert list to numpy array\n",
    "    feature_matrix = np.array(feature_list, dtype='float32')\n",
    "    \n",
    "    # Fit scaler\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(feature_matrix)\n",
    "    \n",
    "    # Build FAISS index\n",
    "    d = scaled_features.shape[1]\n",
    "    index = faiss.IndexFlatL2(d)\n",
    "    index.add(scaled_features)\n",
    "    \n",
    "    return index, scaler, scaled_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_midi(query_file_path, file_names, faiss_index, scaler, k=5):\n",
    "    \"\"\"\n",
    "    Given a query MIDI file and a FAISS index, returns top-k similar files.\n",
    "    \"\"\"\n",
    "    query_feats = extract_features(query_file_path)\n",
    "    if query_feats is None:\n",
    "        print(\"Failed to extract features from query file.\")\n",
    "        return [], []\n",
    "    \n",
    "    query_vector = np.array([\n",
    "        query_feats['tempo'],\n",
    "        query_feats['pitch_mean'],\n",
    "        query_feats['pitch_std'],\n",
    "        query_feats['duration_mean'],\n",
    "        query_feats['duration_std'],\n",
    "        query_feats['ioi_mean'],\n",
    "        query_feats['ioi_std'],\n",
    "        query_feats['syncopation_ratio']\n",
    "    ], dtype='float32').reshape(1, -1)\n",
    "    \n",
    "    # Scale the query with the same scaler\n",
    "    query_scaled = scaler.transform(query_vector)\n",
    "    \n",
    "    # Search top-k\n",
    "    distances, indices = faiss_index.search(query_scaled.astype('float32'), k)\n",
    "    \n",
    "    # Retrieve file names and distances\n",
    "    results_files = [file_names[i] for i in indices[0]]\n",
    "    results_distances = distances[0]\n",
    "    \n",
    "    return results_files, results_distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset_folder):\n",
    "    \"\"\"\n",
    "    Extract features from all MIDI files within a folder structure.\n",
    "    Returns (feature_list, file_names).\n",
    "    \"\"\"\n",
    "    feature_list = []\n",
    "    file_names = []\n",
    "    \n",
    "    for root, _, files in os.walk(dataset_folder):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.mid', '.midi')):\n",
    "                midi_path = os.path.join(root, file)\n",
    "                feats = extract_features(midi_path)\n",
    "                if feats is not None:\n",
    "                    feature_vec = [\n",
    "                        feats['tempo'],\n",
    "                        feats['pitch_mean'],\n",
    "                        feats['pitch_std'],\n",
    "                        feats['duration_mean'],\n",
    "                        feats['duration_std'],\n",
    "                        feats['ioi_mean'],\n",
    "                        feats['ioi_std'],\n",
    "                        feats['syncopation_ratio']\n",
    "                    ]\n",
    "                    feature_list.append(feature_vec)\n",
    "                    file_names.append(midi_path)\n",
    "    \n",
    "    if not feature_list:\n",
    "        raise ValueError(\"No valid MIDI files found in the dataset folder.\")\n",
    "    \n",
    "    return feature_list, file_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": # EXAMPLE USAGE\n",
    "    # Suppose we have a dataset folder\n",
    "    dataset_path = \"/path/to/your/midi/dataset\"\n",
    "    \n",
    "    # Process dataset -> (feature_list, file_names)\n",
    "    feature_list, file_names = process_dataset(dataset_path)\n",
    "    \n",
    "    # Build FAISS index\n",
    "    faiss_index, scaler, _ = build_faiss_index(feature_list)\n",
    "    \n",
    "    # Query\n",
    "    query_midi_path = \"/path/to/query/file.mid\"\n",
    "    k_neighbors = 5\n",
    "    \n",
    "    similar_files, dists = find_similar_midi(query_midi_path, file_names, faiss_index, scaler, k=k_neighbors)\n",
    "    \n",
    "    print(f\"\\nQuery: {query_midi_path}\")\n",
    "    print(f\"Top {k_neighbors} similar files:\")\n",
    "    for fpath, dist in zip(similar_files, dists):\n",
    "        # Optionally convert distance -> similarity ( e.g. 1/(1+dist) )\n",
    "        sim = 1.0 / (1.0 + dist)\n",
    "        print(f\"\\tFile: {fpath} | Distance: {dist:.4f} | Similarity: {sim:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### this is the main carcass of the program backend, let's do unit testing with \"synthetic\" midi's  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_midi(file_path, tempo=120, pitch=60, duration=1.0, velocity=100):\n",
    "    \"\"\"\n",
    "    Creates a simple MIDI file at `file_path` with at least TWO notes:\n",
    "        - A PrettyMIDI object with an initial tempo\n",
    "        - One instrument (non-drum)\n",
    "        - Note #1: pitch, duration, velocity starting at t=0\n",
    "        - Note #2: pitched slightly higher (pitch+2) and starts after note #1\n",
    "    \"\"\"\n",
    "    # Initialize the PrettyMIDI object with the chosen tempo\n",
    "    midi_data = pretty_midi.PrettyMIDI(initial_tempo=tempo)\n",
    "    \n",
    "    # Create an Instrument (program=0 -> Acoustic Grand Piano)\n",
    "    instrument = pretty_midi.Instrument(program=0, is_drum=False)\n",
    "    \n",
    "    # --- Note #1 ---\n",
    "    start_time_1 = 0.0\n",
    "    end_time_1 = start_time_1 + duration\n",
    "    note1 = pretty_midi.Note(\n",
    "        velocity=int(velocity),\n",
    "        pitch=pitch,\n",
    "        start=start_time_1,\n",
    "        end=end_time_1\n",
    "    )\n",
    "    instrument.notes.append(note1)\n",
    "    \n",
    "    # --- Note #2 ---\n",
    "    # Make it start a bit after note #1 ends\n",
    "    start_time_2 = end_time_1 + 0.5\n",
    "    end_time_2 = start_time_2 + duration\n",
    "    note2 = pretty_midi.Note(\n",
    "        velocity=int(velocity),\n",
    "        pitch=pitch + 2,   # Slightly higher pitch\n",
    "        start=start_time_2,\n",
    "        end=end_time_2\n",
    "    )\n",
    "    instrument.notes.append(note2)\n",
    "    \n",
    "    # Add the instrument to the MIDI object\n",
    "    midi_data.instruments.append(instrument)\n",
    "\n",
    "    # Write the final MIDI to file\n",
    "    midi_data.write(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"toy--synthetic-midis\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SYNTHETIC Group A: tempo=120, pitch=60..69\n",
    "for i in range(10):\n",
    "    pitch_value = 60 + i\n",
    "    filename = f\"GroupA_tempo120_pitch{pitch_value}.mid\"\n",
    "    file_path = os.path.join(output_folder, filename)\n",
    "    create_synthetic_midi(file_path, tempo=120, pitch=pitch_value, duration=1.0, velocity=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SYNTHETIC Group B: tempo=90, pitch=50..59\n",
    "for i in range(10):\n",
    "    pitch_value = 50 + i\n",
    "    filename = f\"GroupB_tempo90_pitch{pitch_value}.mid\"\n",
    "    file_path = os.path.join(output_folder, filename)\n",
    "    create_synthetic_midi(file_path, tempo=90, pitch=pitch_value, duration=1.0, velocity=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMidiSimilarityNotebook(unittest.TestCase):\n",
    "\n",
    "    def test_process_dataset(self):\n",
    "        \"\"\"\n",
    "        Test that process_dataset can parse a known folder of synthetic MIDI files\n",
    "        and return the correct number of vectors + file names.\n",
    "        \"\"\"\n",
    "        dataset_folder = \"/Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/testing_tools/clustering/toy--synthetic-midis\"  # adapt path if needed\n",
    "        feature_list, file_names = process_dataset(dataset_folder)\n",
    "        \n",
    "        # Check we have at least 20 MIDI files\n",
    "        self.assertGreaterEqual(len(feature_list), 20, \n",
    "            \"Should have at least 20 valid MIDI feature vectors.\")\n",
    "        self.assertGreaterEqual(len(file_names), 20, \n",
    "            \"Should have at least 20 valid MIDI file names.\")\n",
    "\n",
    "        # Each vector should be 8D (tempo, pitch_mean, pitch_std, duration_mean, duration_std, ioi_mean, ioi_std, syncopation_ratio)\n",
    "        arr = np.array(feature_list)\n",
    "        self.assertEqual(arr.shape[1], 8, \"Feature vectors should have size 8.\")\n",
    "\n",
    "    def test_build_index(self):\n",
    "        \"\"\"\n",
    "        Test that we can build a FAISS index from the synthetic dataset.\n",
    "        \"\"\"\n",
    "        dataset_folder = \"toy--synthetic-midis\"\n",
    "        feature_list, file_names = process_dataset(dataset_folder)\n",
    "        \n",
    "        faiss_index, scaler, scaled_features = build_faiss_index(feature_list)\n",
    "        \n",
    "        # The index should contain as many vectors as we have files\n",
    "        self.assertEqual(faiss_index.ntotal, len(file_names),\n",
    "            \"FAISS index should contain the same number of vectors as files processed.\")\n",
    "        \n",
    "        # Check scaling shape is correct\n",
    "        self.assertEqual(scaled_features.shape, (len(file_names), 8),\n",
    "            \"Scaled feature matrix should match the number of files x 8 features.\")\n",
    "\n",
    "    def test_find_similar_midi(self):\n",
    "        \"\"\"\n",
    "        Test that find_similar_midi can locate the top-k similar files for a known query.\n",
    "        \"\"\"\n",
    "        dataset_folder = \"toy--synthetic-midis\"\n",
    "        feature_list, file_names = process_dataset(dataset_folder)\n",
    "        faiss_index, scaler, scaled_features = build_faiss_index(feature_list)\n",
    "\n",
    "        # Let's pick one file from the synthetic set as a query\n",
    "        # e.g., the first file in the returned list\n",
    "        if file_names:\n",
    "            query_file = file_names[0]\n",
    "            top_k = 5\n",
    "            similar_files, dists = find_similar_midi(query_file, file_names, faiss_index, scaler, k=top_k)\n",
    "            \n",
    "            # Basic checks\n",
    "            self.assertEqual(len(similar_files), top_k, \"Should return k similar files.\")\n",
    "            self.assertEqual(len(dists), top_k, \"Should return k distances.\")\n",
    "            \n",
    "            # The most similar file to itself should be the file itself (distance ~ 0)\n",
    "            self.assertEqual(similar_files[0], query_file,\n",
    "                \"The top match for a file should be itself, with distance near zero.\")\n",
    "        else:\n",
    "            self.skipTest(\"No files found in dataset to test similarity search.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_build_index (__main__.TestMidiSimilarityNotebook.test_build_index)\n",
      "Test that we can build a FAISS index from the synthetic dataset. ... ok\n",
      "test_find_similar_midi (__main__.TestMidiSimilarityNotebook.test_find_similar_midi)\n",
      "Test that find_similar_midi can locate the top-k similar files for a known query. ... ok\n",
      "test_process_dataset (__main__.TestMidiSimilarityNotebook.test_process_dataset)\n",
      "Test that process_dataset can parse a known folder of synthetic MIDI files ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.088s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=3 errors=0 failures=0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run tests \n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestMidiSimilarityNotebook)\n",
    "unittest.TextTestRunner(verbosity=2).run(suite)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's create more synthetic midi, longer ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_diverse_midi_with_name(\n",
    "    group_label,       # \"GroupC\", \"GroupD\", etc.\n",
    "    index,             # 1..10\n",
    "    output_folder,     \n",
    "    tempo_min, \n",
    "    tempo_max,\n",
    "    pitch_min, \n",
    "    pitch_max,\n",
    "    min_notes, \n",
    "    max_notes,\n",
    "    min_duration=0.2, \n",
    "    max_duration=2.0, \n",
    "    min_velocity=40, \n",
    "    max_velocity=100\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a MIDI file with random features, then names the file based on:\n",
    "      - group_label: \"GroupC\", \"GroupD\", \"GroupE\", \"GroupF\"\n",
    "      - index: file index within the group\n",
    "      - final chosen tempo\n",
    "      - average pitch of all notes\n",
    "\n",
    "    The file is placed in output_folder with a name like:\n",
    "      \"GroupC_1_tempo65_avgPitch53.mid\"\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Random tempo\n",
    "    tempo = random.uniform(tempo_min, tempo_max)\n",
    "    midi_data = pretty_midi.PrettyMIDI(initial_tempo=tempo)\n",
    "\n",
    "    # 2) Create an Instrument\n",
    "    instrument = pretty_midi.Instrument(program=0, is_drum=False)\n",
    "\n",
    "    # 3) Decide how many notes to place\n",
    "    n_notes = random.randint(min_notes, max_notes)\n",
    "    \n",
    "    current_time = 0.0\n",
    "    pitches_used = []  # to track pitches for an average\n",
    "\n",
    "    for _ in range(n_notes):\n",
    "        # Random pitch\n",
    "        pitch_val = random.randint(pitch_min, pitch_max)\n",
    "        pitches_used.append(pitch_val)\n",
    "        \n",
    "        # Random note duration\n",
    "        note_duration = random.uniform(min_duration, max_duration)\n",
    "        \n",
    "        # Random velocity\n",
    "        velocity = random.randint(min_velocity, max_velocity)\n",
    "        \n",
    "        # Random gap before next note\n",
    "        gap = random.uniform(0.1, 1.0)\n",
    "        start_time = current_time + gap\n",
    "        end_time = start_time + note_duration\n",
    "        \n",
    "        note = pretty_midi.Note(\n",
    "            velocity=velocity,\n",
    "            pitch=pitch_val,\n",
    "            start=start_time,\n",
    "            end=end_time\n",
    "        )\n",
    "        instrument.notes.append(note)\n",
    "        \n",
    "        current_time = end_time\n",
    "    \n",
    "    midi_data.instruments.append(instrument)\n",
    "\n",
    "    # 4) Compute average pitch\n",
    "    if pitches_used:\n",
    "        avg_pitch = sum(pitches_used)/len(pitches_used)\n",
    "    else:\n",
    "        avg_pitch = 60.0  # fallback if no notes\n",
    "\n",
    "    rounded_tempo = int(round(tempo))\n",
    "    rounded_pitch = int(round(avg_pitch))\n",
    "\n",
    "    # 5) Construct file name with group, index, tempo, avg pitch\n",
    "    file_name = f\"{group_label}_{index}_tempo{rounded_tempo}_avgPitch{rounded_pitch}.mid\"\n",
    "    file_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "    # 6) Write MIDI to disk\n",
    "    midi_data.write(file_path)\n",
    "\n",
    "def generate_synthetic_dataset_by_groups_CDEF(output_folder=\"toy--synthetic-midis\"):\n",
    "    \"\"\"\n",
    "    Creates 4 new groups (C, D, E, F), each with 10 MIDI files.\n",
    "    Each group has distinct tempo + pitch ranges, and final names embed\n",
    "    the chosen tempo & average pitch for easy reference.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Group C: slow tempo, lower pitch\n",
    "    #   tempo 60-70, pitch 50-57, 2-4 notes\n",
    "    for i in range(1, 11):\n",
    "        create_diverse_midi_with_name(\n",
    "            group_label=\"GroupC\",\n",
    "            index=i,\n",
    "            output_folder=output_folder,\n",
    "            tempo_min=60, tempo_max=70,\n",
    "            pitch_min=50, pitch_max=57,\n",
    "            min_notes=2, max_notes=4\n",
    "        )\n",
    "    \n",
    "    # Group D: moderate tempo, mid pitch\n",
    "    #   tempo 80-90, pitch 58-65, 3-5 notes\n",
    "    for i in range(1, 11):\n",
    "        create_diverse_midi_with_name(\n",
    "            group_label=\"GroupD\",\n",
    "            index=i,\n",
    "            output_folder=output_folder,\n",
    "            tempo_min=80, tempo_max=90,\n",
    "            pitch_min=58, pitch_max=65,\n",
    "            min_notes=3, max_notes=5\n",
    "        )\n",
    "\n",
    "    # Group E: medium-fast tempo, higher mid pitch\n",
    "    #   tempo 100-110, pitch 66-73, 4-6 notes\n",
    "    for i in range(1, 11):\n",
    "        create_diverse_midi_with_name(\n",
    "            group_label=\"GroupE\",\n",
    "            index=i,\n",
    "            output_folder=output_folder,\n",
    "            tempo_min=100, tempo_max=110,\n",
    "            pitch_min=66, pitch_max=73,\n",
    "            min_notes=4, max_notes=6\n",
    "        )\n",
    "    \n",
    "    # Group F: fast tempo, high pitch\n",
    "    #   tempo 120-130, pitch 74-81, 5-8 notes\n",
    "    for i in range(1, 11):\n",
    "        create_diverse_midi_with_name(\n",
    "            group_label=\"GroupF\",\n",
    "            index=i,\n",
    "            output_folder=output_folder,\n",
    "            tempo_min=120, tempo_max=130,\n",
    "            pitch_min=74, pitch_max=81,\n",
    "            min_notes=5, max_notes=8\n",
    "        )\n",
    "\n",
    "    print(f\"\\nCreated 40 synthetic MIDIs in '{output_folder}':\")\n",
    "    print(\" - GroupC: 10 files  (tempo ~60-70, pitch 50-57, 2-4 notes)\")\n",
    "    print(\" - GroupD: 10 files  (tempo ~80-90, pitch 58-65, 3-5 notes)\")\n",
    "    print(\" - GroupE: 10 files  (tempo ~100-110, pitch 66-73, 4-6 notes)\")\n",
    "    print(\" - GroupF: 10 files  (tempo ~120-130, pitch 74-81, 5-8 notes)\")\n",
    "    print(\"\\nFile names look like: 'GroupC_1_tempo65_avgPitch53.mid' etc.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 40 synthetic MIDIs in 'toy--synthetic-midis':\n",
      " - GroupC: 10 files  (tempo ~60-70, pitch 50-57, 2-4 notes)\n",
      " - GroupD: 10 files  (tempo ~80-90, pitch 58-65, 3-5 notes)\n",
      " - GroupE: 10 files  (tempo ~100-110, pitch 66-73, 4-6 notes)\n",
      " - GroupF: 10 files  (tempo ~120-130, pitch 74-81, 5-8 notes)\n",
      "\n",
      "File names look like: 'GroupC_1_tempo65_avgPitch53.mid' etc.\n"
     ]
    }
   ],
   "source": [
    "generate_synthetic_dataset_by_groups_CDEF(\"toy--synthetic-midis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestRandomQueriesInSyntheticFolder(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        \"\"\"\n",
    "        Runs once before all tests. We'll build the FAISS index for the entire folder \n",
    "        so we don't have to do it for each individual test.\n",
    "        \"\"\"\n",
    "        cls.dataset_folder = \"/Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/testing_tools/clustering/toy--synthetic-midis\"  # Adjust path if needed\n",
    "        \n",
    "        # Process the synthetic folder: extract features\n",
    "        cls.feature_list, cls.file_names = process_dataset(cls.dataset_folder)\n",
    "        \n",
    "        # Build the FAISS index\n",
    "        cls.faiss_index, cls.scaler, cls.scaled_features = build_faiss_index(cls.feature_list)\n",
    "\n",
    "        if len(cls.file_names) == 0:\n",
    "            raise ValueError(\"No files found in synthetic dataset! Can't run tests.\")\n",
    "        \n",
    "        print(f\"setUpClass: Loaded {len(cls.file_names)} MIDI files.\")\n",
    "    \n",
    "    def test_random_queries(self):\n",
    "        \"\"\"\n",
    "        Randomly selects some files from the synthetic dataset and checks whether\n",
    "        the top neighbors share the same 'Group' label in the filename (like GroupC, GroupD, etc.).\n",
    "        \"\"\"\n",
    "        # We pick, say, 5 random queries\n",
    "        num_random_queries = 5\n",
    "        chosen_files = random.sample(self.file_names, min(num_random_queries, len(self.file_names)))\n",
    "\n",
    "        # For each chosen file, find top k neighbors\n",
    "        k = 5\n",
    "        for query_file in chosen_files:\n",
    "            # Example: \"GroupC_3_tempo65_avgPitch53.mid\"\n",
    "            query_basename = os.path.basename(query_file)\n",
    "            \n",
    "            # Extract the group label from the file name. \n",
    "            # Adjust logic to match your naming pattern:\n",
    "            # e.g., \"GroupC\" is everything from index 0 to index of first underscore\n",
    "            # But if your naming is \"GroupC_3_tempo...\", the group might be the substring:\n",
    "            #   \"GroupC\" = query_basename.split('_')[0]\n",
    "            query_group = query_basename.split('_')[0]  # e.g., \"GroupC\"\n",
    "\n",
    "            similar_files, dists = find_similar_midi(query_file, self.file_names, \n",
    "                                                     self.faiss_index, self.scaler, k=k)\n",
    "\n",
    "            # We'll check how many of the top k neighbors belong to the same group\n",
    "            same_group_count = 0\n",
    "            for f in similar_files:\n",
    "                f_group = os.path.basename(f).split('_')[0]\n",
    "                if f_group == query_group:\n",
    "                    same_group_count += 1\n",
    "            \n",
    "            print(f\"\\nQuery: {query_basename}\")\n",
    "            print(f\"Top {k} neighbors:\")\n",
    "            for fpath, dist in zip(similar_files, dists):\n",
    "                print(f\"  {os.path.basename(fpath)} [dist={dist:.4f}]\")\n",
    "\n",
    "            # We expect at least half (or more) belong to the same group if the features are good\n",
    "            # You can adjust this threshold as desired.\n",
    "            self.assertTrue(same_group_count >= 3,\n",
    "                            f\"We expect at least 3 out of {k} neighbors to share the same group. \"\n",
    "                            f\"Found only {same_group_count} for query '{query_basename}'.\")\n",
    "\n",
    "        # If all random queries pass, we're good!\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_random_queries (__main__.TestRandomQueriesInSyntheticFolder.test_random_queries)\n",
      "Randomly selects some files from the synthetic dataset and checks whether ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_random_queries (__main__.TestRandomQueriesInSyntheticFolder.test_random_queries)\n",
      "Randomly selects some files from the synthetic dataset and checks whether\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/gj/yxv1vk_566l1ws1t_q52nmpm0000gn/T/ipykernel_52592/2454805083.py\", line 61, in test_random_queries\n",
      "    self.assertTrue(same_group_count >= 3,\n",
      "AssertionError: False is not true : We expect at least 3 out of 5 neighbors to share the same group. Found only 1 for query 'GroupD_6_tempo80_avgPitch62.mid'.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.033s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setUpClass: Loaded 60 MIDI files.\n",
      "\n",
      "Query: GroupD_6_tempo80_avgPitch62.mid\n",
      "Top 5 neighbors:\n",
      "  GroupD_6_tempo80_avgPitch62.mid [dist=0.0000]\n",
      "  GroupC_2_tempo66_avgPitch54.mid [dist=3.5033]\n",
      "  GroupE_10_tempo103_avgPitch70.mid [dist=4.0793]\n",
      "  GroupC_10_tempo62_avgPitch54.mid [dist=4.3273]\n",
      "  GroupE_7_tempo104_avgPitch70.mid [dist=4.4486]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=1>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestRandomQueriesInSyntheticFolder)\n",
    "unittest.TextTestRunner(verbosity=2).run(suite) # run the tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this happens becaus of pitch variance most probably"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
