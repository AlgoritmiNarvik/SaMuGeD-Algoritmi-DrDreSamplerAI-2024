{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have dataset from Asle, processed with 2 pointers to find repeatitions in Lakh MIDI Clean midi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_datasets_folder(root_dir='/datasets'):\n",
    "    \"\"\"\n",
    "    Analyzes the dataset folder and provides statistics about the number of files, MIDI files, and file extension distribution.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): The root directory of the dataset. Default is '/datasets'.\n",
    "    \"\"\"\n",
    "    total_files = 0\n",
    "    midi_files = 0\n",
    "    folder_count = 0\n",
    "    file_extensions = Counter()\n",
    "\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        folder_count += 1\n",
    "        total_files += len(files)\n",
    "        \n",
    "        for file in files:\n",
    "            _, ext = os.path.splitext(file)\n",
    "            if ext:\n",
    "                file_extensions[ext.lower()] += 1\n",
    "            else:\n",
    "                file_extensions['(no extension)'] += 1\n",
    "            \n",
    "            if ext.lower() in ['.mid', '.midi']:\n",
    "                midi_files += 1\n",
    "\n",
    "    print(f\"Total number of folders: {folder_count}\")\n",
    "    print(f\"Total number of files: {total_files}\")\n",
    "    print(f\"Number of MIDI files: {midi_files}\")\n",
    "    \n",
    "    print(\"\\nFile extension distribution:\")\n",
    "    for ext, count in file_extensions.most_common():\n",
    "        print(f\"{ext}: {count}\")\n",
    "    \n",
    "    print(\"\\nPercentage breakdown:\")\n",
    "    sorted_extensions = sorted(file_extensions.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for ext, count in sorted_extensions[:5]:  # Show top 5 extensions\n",
    "        percentage = (count / total_files) * 100\n",
    "        print(f\"{ext}: {percentage:.2f}%\")\n",
    "\n",
    "    other_count = sum(count for ext, count in sorted_extensions[5:])\n",
    "    other_percentage = (other_count / total_files) * 100\n",
    "    print(f\"Others: {other_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n",
      "drwxr-xr-x@ 3 serdegsenere  staff   96 Sep 26 12:56 \u001b[34m.\u001b[m\u001b[m\n",
      "drwxr-xr-x  7 serdegsenere  staff  224 Sep 26 12:55 \u001b[34m..\u001b[m\u001b[m\n",
      "-rw-r--r--@ 1 serdegsenere  staff    0 Sep 26 12:56 Clustering_repeated_motifs.ipynb\n"
     ]
    }
   ],
   "source": [
    "# checking the dataset folder's path\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/testing_tools/clustering'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ipynb has different paths concept, ok, let's use full path instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of folders: 3484\n",
      "Total number of files: 7669\n",
      "Number of MIDI files: 7662\n",
      "\n",
      "File extension distribution:\n",
      ".mid: 7662\n",
      "(no extension): 7\n",
      "\n",
      "Percentage breakdown:\n",
      ".mid: 99.91%\n",
      "(no extension): 0.09%\n",
      "Others: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# checking the dataset folder, NOTE that it is in gitignore, so it is not pushed to github\n",
    "analyze_datasets_folder(\"/Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/datasets/two_pointers_repeats_only\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plan for this ipynb something like this\n",
    "\n",
    "\t1.\tPreprocessing\n",
    "\t\t\tParsing MIDI files with mido or better pretty_midi\n",
    "\t\t\tExtract key features -- note sequences, rhythm, harmony\n",
    "\t\t\tNormalize key and tempo\n",
    "\t2.\tFeature representation\n",
    "\t\t\tConvert MIDI files to fixed-length vectors (bag-of-notes, TF-IDF, autoencoders??)\n",
    "\t\t\tUse dimensionality reduction if needed?\n",
    "\t3.\tSimilarity measurement\n",
    "\t\t\tDistance metrics like Euclidean, Cosine, DTW\n",
    "\t4.\tEfficient retrieval\n",
    "\t\t\tIndexing structures like FAISS or LSH for fast searches?\n",
    "\t5.\tBuilding the program for integreation later\n",
    "\n",
    "(add references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mido in /Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/myenv/lib/python3.12/site-packages (1.3.2)\n",
      "Requirement already satisfied: packaging~=23.1 in /Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/myenv/lib/python3.12/site-packages (from mido) (23.2)\n",
      "Requirement already satisfied: pretty_midi in /Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/myenv/lib/python3.12/site-packages (0.2.10)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/myenv/lib/python3.12/site-packages (from pretty_midi) (2.0.0)\n",
      "Requirement already satisfied: mido>=1.1.16 in /Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/myenv/lib/python3.12/site-packages (from pretty_midi) (1.3.2)\n",
      "Requirement already satisfied: six in /Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/myenv/lib/python3.12/site-packages (from pretty_midi) (1.16.0)\n",
      "Requirement already satisfied: packaging~=23.1 in /Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/myenv/lib/python3.12/site-packages (from mido>=1.1.16->pretty_midi) (23.2)\n",
      "Requirement already satisfied: numpy in /Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/myenv/lib/python3.12/site-packages (2.0.0)\n",
      "Requirement already satisfied: pandas in /Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/myenv/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/myenv/lib/python3.12/site-packages (from pandas) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/myenv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/myenv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/myenv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/myenv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/myenv/lib/python3.12/site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/myenv/lib/python3.12/site-packages (from scikit-learn) (2.0.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/myenv/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/myenv/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/myenv/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0.post1-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.7 kB)\n",
      "Collecting numpy<2.0,>=1.0 (from faiss-cpu)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: packaging in /Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/myenv/lib/python3.12/site-packages (from faiss-cpu) (23.2)\n",
      "Downloading faiss_cpu-1.8.0.post1-cp312-cp312-macosx_11_0_arm64.whl (6.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, faiss-cpu\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.0\n",
      "    Uninstalling numpy-2.0.0:\n",
      "      Successfully uninstalled numpy-2.0.0\n",
      "Successfully installed faiss-cpu-1.8.0.post1 numpy-1.26.4\n"
     ]
    }
   ],
   "source": [
    "!pip install mido\n",
    "!pip install pretty_midi\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install faiss-cpu  # for similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "import faiss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    \"\"\"\n",
    "    Extract features from a MIDI file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the MIDI file.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A feature vector representing the MIDI file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        midi_data = pretty_midi.PrettyMIDI(file_path)\n",
    "    except:\n",
    "        print(f\"Error loading {file_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Initialize lists to hold features\n",
    "    pitches = []\n",
    "    durations = []\n",
    "    velocities = []\n",
    "    \n",
    "    for instrument in midi_data.instruments:\n",
    "        if not instrument.is_drum:\n",
    "            for note in instrument.notes:\n",
    "                pitches.append(note.pitch)\n",
    "                durations.append(note.end - note.start)\n",
    "                velocities.append(note.velocity)\n",
    "    \n",
    "    if not pitches:\n",
    "        return None  # Skip files with no notes\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    pitches = np.array(pitches)\n",
    "    durations = np.array(durations)\n",
    "    velocities = np.array(velocities)\n",
    "    \n",
    "    # Combine features into a single vector\n",
    "    feature_vector = np.concatenate((pitches, durations, velocities))\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset_folder):\n",
    "    \"\"\"\n",
    "    Process a dataset folder and extract features from all MIDI files.\n",
    "\n",
    "    Args:\n",
    "        dataset_folder (str): The path to the dataset folder.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two lists - feature_list and file_names.\n",
    "    \"\"\"\n",
    "    feature_list = []\n",
    "    file_names = []\n",
    "\n",
    "    for root, _, files in os.walk(dataset_folder):\n",
    "        for file_name in files:\n",
    "            if file_name.lower().endswith(('.mid', '.midi')):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                features = extract_features(file_path)\n",
    "                if features is not None:\n",
    "                    feature_list.append(features)\n",
    "                    file_names.append(file_path)\n",
    "                else:\n",
    "                    print(f\"Skipping {file_name} due to extraction issues.\")\n",
    "    \n",
    "    return feature_list, file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that this folder is in gitignore, so it is not pushed to github, I took it from Teams\n",
    "dataset_folder = \"/Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/datasets/two_pointers_repeats_only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/datasets/two_pointers_repeats_only/Limp_Bizkit_Patterns/Stuck.mid/track1.mid',\n",
       " '/Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/datasets/two_pointers_repeats_only/Limp_Bizkit_Patterns/Stuck.mid/track0.mid',\n",
       " '/Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/datasets/two_pointers_repeats_only/Limp_Bizkit_Patterns/Faith.mid/track2.mid',\n",
       " '/Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/datasets/two_pointers_repeats_only/Limp_Bizkit_Patterns/Faith.mid/track1.mid',\n",
       " '/Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/datasets/two_pointers_repeats_only/Limp_Bizkit_Patterns/Faith.mid/track0.mid']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try to process only a part of the dataset\n",
    "feature_list, file_names = process_dataset(\"/Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/datasets/two_pointers_repeats_only/Limp_Bizkit_Patterns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see the first 10 file names\n",
    "len(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total files itn the folder is 22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/datasets/two_pointers_repeats_only/Limp_Bizkit_Patterns/Stuck.mid/track1.mid',\n",
       " '/Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/datasets/two_pointers_repeats_only/Limp_Bizkit_Patterns/Stuck.mid/track0.mid',\n",
       " '/Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/datasets/two_pointers_repeats_only/Limp_Bizkit_Patterns/Faith.mid/track2.mid',\n",
       " '/Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/datasets/two_pointers_repeats_only/Limp_Bizkit_Patterns/Faith.mid/track1.mid',\n",
       " '/Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/datasets/two_pointers_repeats_only/Limp_Bizkit_Patterns/Faith.mid/track0.mid',\n",
       " '/Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/datasets/two_pointers_repeats_only/Limp_Bizkit_Patterns/N_2_Gether_Now.mid/track1.mid',\n",
       " '/Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/datasets/two_pointers_repeats_only/Limp_Bizkit_Patterns/N_2_Gether_Now.mid/track0.mid',\n",
       " '/Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/datasets/two_pointers_repeats_only/Limp_Bizkit_Patterns/Nookie.mid/track2.mid',\n",
       " '/Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/datasets/two_pointers_repeats_only/Limp_Bizkit_Patterns/Nookie.mid/track3.mid',\n",
       " '/Volumes/C/Algoritmi/SaMuGeD-Algoritmi-DrDreSamplerAI-2024/datasets/two_pointers_repeats_only/Limp_Bizkit_Patterns/Nookie.mid/track1.mid']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see 10 files\n",
    "print(\"total files itn the folder is \" + str(len(file_names)))\n",
    "file_names[0:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 38.        ,  45.        ,  50.        ,  38.        ,\n",
       "         45.        ,  50.        ,  47.        ,  54.        ,\n",
       "         59.        ,  46.        ,  53.        ,  58.        ,\n",
       "         38.        ,  45.        ,  50.        ,  38.        ,\n",
       "         45.        ,  50.        ,  40.        ,  47.        ,\n",
       "         52.        ,  38.        ,  45.        ,  41.        ,\n",
       "         48.        ,  53.        ,  38.        ,  45.        ,\n",
       "         40.        ,  47.        ,  52.        ,  41.        ,\n",
       "         48.        ,  53.        ,  49.        ,  50.        ,\n",
       "         38.        ,  49.        ,  50.        ,  38.        ,\n",
       "         49.        ,  50.        ,  38.        ,  49.        ,\n",
       "         50.        ,  38.        ,  49.        ,  50.        ,\n",
       "         49.        ,  50.        ,  50.        ,  57.        ,\n",
       "         62.        ,  51.        ,  58.        ,  63.        ,\n",
       "         50.        ,  57.        ,  62.        ,  51.        ,\n",
       "         58.        ,  63.        ,  63.        ,  45.        ,\n",
       "         50.        ,  57.        ,  62.        ,  46.        ,\n",
       "         51.        ,  58.        ,  63.        ,  45.        ,\n",
       "         50.        ,  57.        ,  62.        ,  50.        ,\n",
       "         57.        ,  62.        ,  46.        ,  51.        ,\n",
       "         58.        ,  63.        ,  45.        ,  50.        ,\n",
       "         57.        ,  62.        ,  46.        ,  51.        ,\n",
       "         58.        ,  63.        ,   0.13822114,   0.13822114,\n",
       "          0.13822114,   0.13822114,   0.13822114,   0.13822114,\n",
       "          0.28245189,   0.28245189,   0.28245189,   0.28245189,\n",
       "          0.28245189,   0.28245189,   0.13822114,   0.13822114,\n",
       "          0.13822114,   0.13822114,   0.13822114,   0.13822114,\n",
       "          0.28245189,   0.28245189,   0.28245189,   0.13822114,\n",
       "          0.13822114,   0.28245189,   0.28245189,   0.28245189,\n",
       "          0.13822114,   0.13822114,   0.13822114,   0.13822114,\n",
       "          0.13822114,   0.13822114,   0.13822114,   0.13822114,\n",
       "          0.13822114,   0.13822114,   0.13822114,   0.13822114,\n",
       "          0.13822114,   0.13822114,   0.13822114,   0.13822114,\n",
       "          0.13822114,   0.13822114,   0.13822114,   0.13822114,\n",
       "          0.13822114,   0.13822114,   0.13822114,   0.13822114,\n",
       "          0.28245189,   0.28245189,   0.28245189,   0.28245189,\n",
       "          0.28245189,   0.28245189,   0.28245189,   0.28245189,\n",
       "          0.28245189,   0.28245189,   0.28245189,   0.28245189,\n",
       "          0.28245189,   0.28245189,   0.28245189,   0.28245189,\n",
       "          0.28245189,   0.28245189,   0.28245189,   0.28245189,\n",
       "          0.28245189,   0.28245189,   0.28245189,   0.28245189,\n",
       "          0.28245189,   0.28245189,   0.28245189,   0.28245189,\n",
       "          0.28245189,   0.28245189,   0.28245189,   0.28245189,\n",
       "          0.28245189,   0.28245189,   0.28245189,   0.28245189,\n",
       "          0.28245189,   0.28245189,   0.28245189,   0.28245189,\n",
       "        110.        , 110.        , 110.        , 110.        ,\n",
       "        110.        , 110.        , 110.        , 110.        ,\n",
       "        110.        , 110.        , 110.        , 110.        ,\n",
       "        110.        , 110.        , 110.        , 110.        ,\n",
       "        110.        , 110.        , 110.        , 110.        ,\n",
       "        110.        , 110.        , 110.        , 110.        ,\n",
       "        110.        , 110.        , 110.        , 110.        ,\n",
       "        110.        , 110.        , 110.        , 110.        ,\n",
       "        110.        , 110.        , 110.        , 110.        ,\n",
       "        110.        , 110.        , 110.        , 110.        ,\n",
       "        110.        , 110.        , 110.        , 110.        ,\n",
       "        110.        , 110.        , 110.        , 110.        ,\n",
       "        110.        , 110.        , 110.        , 110.        ,\n",
       "        110.        , 110.        , 110.        , 110.        ,\n",
       "        110.        , 110.        , 110.        , 110.        ,\n",
       "        110.        , 110.        , 110.        , 110.        ,\n",
       "        110.        , 110.        , 110.        , 110.        ,\n",
       "        110.        , 110.        , 110.        , 110.        ,\n",
       "        110.        , 110.        , 110.        , 110.        ,\n",
       "        110.        , 110.        , 110.        , 110.        ,\n",
       "        110.        , 110.        , 110.        , 110.        ,\n",
       "        110.        , 110.        , 110.        , 110.        ,\n",
       "        110.        , 110.        ])]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector of features for the 1st file\n",
    "feature_list[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 270)\n",
      "(1, 204)\n",
      "(1, 108)\n"
     ]
    }
   ],
   "source": [
    "# let's see the shape of the 1st, 2nd and 3rd file\n",
    "print(np.shape(feature_list[0:1]))  \n",
    "print(np.shape(feature_list[1:2]))\n",
    "print(np.shape(feature_list[2:3]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oi, oi oi, this difference in vector sizes will create problems as many ML algorithms expect fixed length inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using fixed length: 288\n"
     ]
    }
   ],
   "source": [
    "# analyzing the lengths of the feature vectors\n",
    "feature_lengths = [len(f) for f in feature_list]\n",
    "fixed_length = min(6666, max(feature_lengths))  # set an upper limit here\n",
    "print(f\"Using fixed length: {fixed_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_or_truncate(features, fixed_length):\n",
    "    \"\"\"\n",
    "    Pad or truncate the feature vector to the fixed length.\n",
    "\n",
    "    Args:\n",
    "        features (numpy.ndarray): The feature vector to pad or truncate.\n",
    "        fixed_length (int): The length to which the feature vector should be padded or truncated.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The padded or truncated feature vector.\n",
    "    \"\"\"\n",
    "    if len(features) >= fixed_length:\n",
    "        return features[:fixed_length]\n",
    "    else:\n",
    "        padding = np.zeros(fixed_length - len(features))\n",
    "        return np.concatenate((features, padding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to all feature vectors\n",
    "processed_features = [pad_or_truncate(f, fixed_length) for f in feature_list]\n",
    "processed_features = np.array(processed_features)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "processed_features = scaler.fit_transform(processed_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Search Index\n",
    "FAISS for efficient similarity searches in high-dimensional spaces\n",
    "\n",
    "FAISS -- Facebook AI Similarity Search (https://ai.meta.com/tools/faiss/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features to float32 as required by FAISS\n",
    "processed_features = processed_features.astype('float32')\n",
    "\n",
    "# Use PCA to reduce dimensionality for efficiency\n",
    "pca_dimensions = 256  # adjust based on performance\n",
    "pca = PCA(n_components=pca_dimensions)\n",
    "processed_features_pca = pca.fit_transform(processed_features)\n",
    "\n",
    "# Initialize the FAISS index\n",
    "dimension = pca_dimensions\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Add vectors to the index\n",
    "index.add(processed_features_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
